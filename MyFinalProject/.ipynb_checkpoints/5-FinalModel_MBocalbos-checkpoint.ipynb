{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0424837807992412"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_train = pd.read_feather('./X_train.feather')\n",
    "y_train = pd.read_feather('./y_train.feather')['shares']\n",
    "\n",
    "X_val = pd.read_feather('./X_val.feather')\n",
    "y_val = pd.read_feather('./y_val.feather')['shares']\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=42, max_features='log2', min_samples_leaf=46)\n",
    "rfr.fit(X_train, y_train)\n",
    "rfr.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['n_unique_tokens', 'num_hrefs', 'num_imgs', 'num_videos', 'kw_avg_max',\n",
       "       'kw_min_avg', 'kw_avg_avg', 'self_reference_min_shares',\n",
       "       'self_reference_max_shares', 'LDA_03', 'avg_negative_polarity',\n",
       "       'data_channel_missing'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After going through all of the steps to select the best model to predict the number of shares, that is, hyperparameter tuning, determining feature importances, correlations analysis, and focused feature engineering, the final model was selected and this model and has 12 features. The 12 features are shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_feather('./X_test.feather')\n",
    "y_test = pd.read_feather('./y_test.feather')['shares']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7909,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7909, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013597095072079513"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, after validating my model, I got a significant drop on my score (from 0.04 to 0.01)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression vs. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although my linear regression model had a higher score than my random forest model, I think that the random forest model in this instance works better than the linear regression model. For the linear regression model, I ended up using 50 features and still getting a low score of 0.13 while with random forest, although the score is lower, I am only using 12 feature variables. The recommendation is to do more feature engineering of variables that will be able to explain the target variable or, in addition explore more on the relationships of the feature variables with the target variable because the relationship may not be really linear at all which is probably the reason why the linear regression model was not quite effective. With linear regression modeling, it was more difficult to come up with the best model because you even have to check for outliers and also try to transform the data in order to get a better score. We do not have to do this part with random forest. Lastly, it is easier to see the impact of the feature variables with the target variable in the end especially that you only are working with a few features. Using the different visualizations, you can see that the effect of each variable is not always linear and also you can really see the effect of increasing from one unit to another. Unlike with linear regression that always assumes a linear relationship which may not always be the case for each variable and dataset that you have."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
